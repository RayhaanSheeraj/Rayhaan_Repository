{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "layout: post\n",
    "title: Computing Bias\n",
    "description: Popcorn and Homework Hacks\n",
    "categories: [Tri 3 Team Teach Hacks]\n",
    "permalink: /ComputingBias/\n",
    "type: collab\n",
    "comments: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popcorn Hacks\n",
    "\n",
    "### Popcorn Hack 1\n",
    "\n",
    "**Example:**  \n",
    "A movie that shows bias is Aladdin.\n",
    "\n",
    "**Who is affected:**  \n",
    "\n",
    "\n",
    "The movie shows Middle Eastern cultures in a stereotypical and sometimes negative way, which can affect how viewers see people from these cultures.\n",
    "\n",
    "**Potential cause of this bias:**  \n",
    "This bias might come from the filmmakers using stereotypes and not checking with people from Middle Eastern cultures.\n",
    "\n",
    "### Popcorn Hack 2\n",
    "\n",
    "**Example:**  \n",
    "I once used a website that wasn't mobile friendly. The text was too small to read, and the buttons were hard to click on my phone. It made me feel annoyed and excluded because I was on phone. One way to improve this technology is to design websites to be responsive, so they work well on all devices, including phones and tablets.\n",
    "\n",
    "### Popcorn Hack 3\n",
    "\n",
    "**Example:**  \n",
    "When designing a fitness tracking app, bias could sneak in by not considering users with different physical abilities, ages, or health conditions. To make the app fair for everyone, you could add features like customizable workout plans, adjustable difficulty levels, and options to input personal health information. This way, the app can give recommendations that fit each user's unique needs and abilities.\n",
    "\n",
    "## Homework Hacks\n",
    "\n",
    "### Homework Hack 1\n",
    "\n",
    "**Example:**  \n",
    "A digital tool I use regularly is YouTube.\n",
    "\n",
    "**Identify Potential Bias:**  \n",
    "YouTube's recommendation system sometimes shows a pattern of promoting similar types of content, which might not cater well to different user groups like age, gender, or language.\n",
    "\n",
    "**Analyze the Cause:**  \n",
    "This bias might be caused by the algorithm favoring popular content and not having enough diverse data or testing.\n",
    "\n",
    "**Propose a Solution:**  \n",
    "One way to reduce bias is to improve the algorithm to consider a wider range of content and user preferences. Additionally, involving a diverse group of testers can help ensure the platform caters well to all user groups."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
